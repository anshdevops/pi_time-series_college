{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use ``auto_arima`` to fit an ARIMA model to perform forecasting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pmdarima in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (2.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.9.1)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.4.4)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (0.13.2)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.26.11)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.0.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (63.4.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (0.29.32)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pmdarima) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.19->pmdarima) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.13.2->pmdarima) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.50.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.11.23)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: arch in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from arch) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from arch) (1.4.4)\n",
      "Requirement already satisfied: statsmodels>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from arch) (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from arch) (1.9.1)\n",
      "Requirement already satisfied: property-cached>=1.6.4 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from arch) (1.6.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->arch) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0->arch) (2.8.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.11->arch) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11->arch) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.11->arch) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima\n",
    "import pmdarima\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils import plot_PIs, compute_coverage_len\n",
    "!pip install tensorflow\n",
    "import data_loaders\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "!pip install arch\n",
    "import arch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "\n",
    "In this example, we consider solar energy production data. We specify the forecast ``horizon`` variable and the main ``seasonality`` in the time series (in this case ``seasonality=24`` since the data have hourly resolution). We also specify the ``target`` variable that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_15696\\3500290544.py:2: UserWarning: Parsing '31/07/2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  train_df, _, test_df = data_loaders.get_solar_data()\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_df, _, test_df = data_loaders.get_solar_data()\n",
    "horizon=24\n",
    "seasonality=24\n",
    "target='MWH'\n",
    "\n",
    "# we use a subset of the actual dataset in this example \n",
    "train_df = train_df[:2000]\n",
    "test_df = test_df[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we separate the target variable from the other variables, which are used as exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (2000,), x_train: (2000, 5), y_test: (1000,), x_test: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "# separate exogenous variables (x) from the target variable (y)\n",
    "y_train = train_df[target].values\n",
    "x_train = train_df.drop(target, axis=1).values\n",
    "y_test = test_df[target].values\n",
    "x_test = test_df.drop(target, axis=1).values\n",
    "\n",
    "print(f\"y_train: {y_train.shape}, x_train: {x_train.shape}, y_test: {y_test.shape}, x_test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we normalize the data in the range $[-1,1]$. We use a different scaler for the exogenous variables ($x$) and the target variable ($y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the scaler\n",
    "y_scaler = MinMaxScaler()\n",
    "x_scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize data\n",
    "y_train = y_scaler.fit_transform(y_train[...,None])\n",
    "x_train = x_scaler.fit_transform(x_train)\n",
    "y_test = y_scaler.transform(y_test[...,None])\n",
    "x_test = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA model\n",
    "\n",
    "### Fit the ARIMA model\n",
    "We use ``auto_arima`` to find the best ARIMA model for the data at hand. The procedure takes a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,1,1)[24]             : AIC=inf, Time=6.96 sec\n",
      " ARIMA(0,1,0)(0,1,0)[24]             : AIC=-2737.628, Time=0.15 sec\n",
      " ARIMA(1,1,0)(1,1,0)[24]             : AIC=-3064.876, Time=1.50 sec\n",
      " ARIMA(0,1,1)(0,1,1)[24]             : AIC=inf, Time=6.69 sec\n",
      " ARIMA(1,1,0)(0,1,0)[24]             : AIC=-2739.765, Time=0.32 sec\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 83.6 MiB for an array with shape (74, 74, 2000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_15696\\2102308459.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# automatically fit the optimal ARIMA model for given time series\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m arima_model = pmdarima.auto_arima(\n\u001B[0m\u001B[0;32m      3\u001B[0m     \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexogenous\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mstart_p\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart_q\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mmax_p\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_q\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mseasonality\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\auto.py\u001B[0m in \u001B[0;36mauto_arima\u001B[1;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001B[0m\n\u001B[0;32m    699\u001B[0m         )\n\u001B[0;32m    700\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 701\u001B[1;33m     \u001B[0msorted_res\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msearch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msolve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    702\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0m_return_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msorted_res\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_valid_fits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\_auto_solvers.py\u001B[0m in \u001B[0;36msolve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    343\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mP\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mmax_P\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    344\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mk\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_k\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 345\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mP\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mD\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mQ\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    346\u001B[0m                 \u001B[0mP\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    347\u001B[0m                 \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\_auto_solvers.py\u001B[0m in \u001B[0;36m_do_fit\u001B[1;34m(self, order, seasonal_order, constant)\u001B[0m\n\u001B[0;32m    231\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mk\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 233\u001B[1;33m             fit, fit_time, new_ic = self._fit_arima(\n\u001B[0m\u001B[0;32m    234\u001B[0m                 \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    235\u001B[0m                 \u001B[0mseasonal_order\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mseasonal_order\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\_auto_solvers.py\u001B[0m in \u001B[0;36m_fit_candidate_model\u001B[1;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    505\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 506\u001B[1;33m         \u001B[0mfit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    507\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    508\u001B[0m     \u001B[1;31m# for non-stationarity errors or singular matrices, return None\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\arima.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, y, X, **fit_args)\u001B[0m\n\u001B[0;32m    601\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    602\u001B[0m         \u001B[1;31m# Internal call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 603\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    604\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    605\u001B[0m         \u001B[1;31m# now make a forecast if we're validating to compute the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\arima.py\u001B[0m in \u001B[0;36m_fit\u001B[1;34m(self, y, X, **fit_args)\u001B[0m\n\u001B[0;32m    522\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatch_warnings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecord\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m                 \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msimplefilter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ignore'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 524\u001B[1;33m                 \u001B[0mfit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marima_res_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_fit_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    525\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    526\u001B[0m             \u001B[0mfit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marima_res_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_fit_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pmdarima\\arima\\arima.py\u001B[0m in \u001B[0;36m_fit_wrapper\u001B[1;34m()\u001B[0m\n\u001B[0;32m    508\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    509\u001B[0m             \u001B[0mdisp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfit_args\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"disp\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 510\u001B[1;33m             fitted = arima.fit(\n\u001B[0m\u001B[0;32m    511\u001B[0m                 \u001B[0mstart_params\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstart_params\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001B[0m\n\u001B[0;32m    726\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    727\u001B[0m                 \u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msmooth\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 728\u001B[1;33m             res = func(mlefit.params, transformed=False, includes_fixed=False,\n\u001B[0m\u001B[0;32m    729\u001B[0m                        cov_type=cov_type, cov_kwds=cov_kwds)\n\u001B[0;32m    730\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py\u001B[0m in \u001B[0;36msmooth\u001B[1;34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    885\u001B[0m         \u001B[1;31m# Get the state space output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 886\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mssm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msmooth\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcomplex_step\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcomplex_step\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    887\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;31m# Wrap in a results object\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py\u001B[0m in \u001B[0;36msmooth\u001B[1;34m(self, smoother_output, smooth_method, results, run_filter, prefix, complex_step, update_representation, update_filter, update_smoother, **kwargs)\u001B[0m\n\u001B[0;32m    412\u001B[0m         \u001B[1;31m# Update the results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    413\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mupdate_smoother\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 414\u001B[1;33m             \u001B[0mresults\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate_smoother\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msmoother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    415\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    416\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py\u001B[0m in \u001B[0;36mupdate_smoother\u001B[1;34m(self, smoother)\u001B[0m\n\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m         self.innovations_transition = (\n\u001B[1;32m--> 672\u001B[1;33m             np.array(smoother.innovations_transition, copy=True))\n\u001B[0m\u001B[0;32m    673\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    674\u001B[0m         \u001B[1;31m# Diffuse objects\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 83.6 MiB for an array with shape (74, 74, 2000) and data type float64"
     ]
    }
   ],
   "source": [
    "# automatically fit the optimal ARIMA model for given time series\n",
    "arima_model = pmdarima.auto_arima(\n",
    "    y_train, exogenous=x_train,\n",
    "    start_p=1, start_q=1,\n",
    "    max_p=4, max_q=4, m=seasonality,\n",
    "    start_P=0, seasonal=True,\n",
    "    d=1, D=1, trace=True,\n",
    "    error_action='ignore',   # don't want to know if an order does not work\n",
    "    suppress_warnings=True,  # don't want convergence warnings\n",
    "    stepwise=True)\n",
    "print(arima_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is fit, we collect the training residuals $\\epsilon_t = \\hat{y}_t - y_t$. The residuals give us an idea of how well the ARIMA model fits the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect training residuals\n",
    "train_res = arima_model.arima_res_.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residuals and training data\n",
    "plt.plot(y_train[100:500], label='y_train')\n",
    "plt.plot(train_res[100:500], label='train_res')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the residuals should be pure noise and, thus, uncorrelated with each other. To check this, we look at the autocorrelation and partial autocorrelation plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_train_res = train_res**2 \n",
    "plot_acf(squared_train_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(squared_train_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are some correlations left in the residuals, meaning that the ARIMA model was not able to fully explain the variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions\n",
    "\n",
    "Now that the model is fit, we can use it to make predictions at ``horizon`` steps ahead. After making each prediction, we update the ARIMA model with the new data as they become available. Also, we collect the residuals on the test data and the CI at the $\\alpha=0.1$ confidence level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and update the model\n",
    "pred_list, ci_list, res_list = [], [], []\n",
    "for step in tqdm(range(y_test.shape[0]//horizon)):\n",
    "    y_hat, conf_int = arima_model.predict(n_periods=horizon, return_conf_int=True, alpha=0.1)\n",
    "    pred_list.append(y_hat)\n",
    "    ci_list.append(conf_int)\n",
    "    res_list.append(y_test[step*horizon:(step+1)*horizon, 0] - y_hat)\n",
    "    arima_model.update(\n",
    "        y_test[step*horizon:(step+1)*horizon], \n",
    "        exogenous=x_test[step*horizon:(step+1)*horizon])\n",
    "    \n",
    "# collect predictions, CI, and residuals\n",
    "preds = np.hstack(pred_list)[...,None]\n",
    "preds_ci = np.vstack(ci_list)\n",
    "test_res = np.hstack(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process output\n",
    "y_hat = y_scaler.inverse_transform(preds)\n",
    "y_hat_ci = y_scaler.inverse_transform(preds_ci)\n",
    "y_test = y_scaler.inverse_transform(y_test[:preds.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and print arima results\n",
    "plot_PIs(y_test[:preds.shape[0]], y_hat, y_hat_ci[:,0], y_hat_ci[:,1], x_lims=[168,336])\n",
    "compute_coverage_len(y_test[:preds.shape[0],0], y_hat_ci[:,0], y_hat_ci[:,1], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCH models (bonus)\n",
    "\n",
    "ARIMA models do not model a change in the variance over time. On the other hand, an ARCH method models the variance at a time step as a function of the residual errors from a mean process. ARCH expects the series to be stationary (besides the change in variance) meaning it does not have a trend or seasonal component.\n",
    "In practice, ARCH can be used to model the variance of the residuals obtained from an ARIMA model:\n",
    "\n",
    "$$\n",
    "\\epsilon_t = z_t \\sigma_t \\;\\; \\text{with} \\;\\; \\sigma_t = \\sqrt{\\alpha_0 + \\sum_{i=1}^p \\alpha_i \\epsilon_{t-i}^2}\n",
    "$$\n",
    "\n",
    "Generalized Autoregressive Conditional Heteroskedasticity (GARCH), is an extension of the ARCH model that incorporates a MA component together with the AR component.\n",
    "The introduction of a MA component allows GARCH to model the variance not only as a function of the previous values $\\epsilon_{t-i}$, but also as a function of the previous variances $\\sigma^2_{t-j}$:\n",
    "\n",
    "$$\n",
    "\\sigma_t = \\sqrt{\\alpha_0 + \\sum_{i=1}^p \\alpha_i \\epsilon_{t-i}^2 + \\sum_{j=1}^q \\beta_j \\sigma^2_{t-j}}\n",
    "$$\n",
    "\n",
    "where $p$ is the number of lag residuals and $q$ the number of lag variances.\n",
    "In this example, we set $p=1$ and $q=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_res = np.concatenate((train_res, test_res))\n",
    "\n",
    "# specify garch model\n",
    "garch = arch.arch_model(\n",
    "    tot_res, \n",
    "    vol='garch', \n",
    "    p=1, q=2)\n",
    "\n",
    "# fit the garch model\n",
    "garch_fitted = garch.fit(\n",
    "    last_obs=train_res.shape[0] # specify where train data ends\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasts with garch\n",
    "garch_forecast = garch_fitted.forecast(\n",
    "    start=train_res.shape[0], # specify where forecasting starts\n",
    "    horizon=horizon, \n",
    "    )\n",
    "\n",
    "garch_var = garch_forecast.variance['h.'+str(horizon)].iloc[train_res.shape[0]:].values\n",
    "garch_mean = garch_forecast.mean['h.'+str(horizon)].iloc[-test_res.shape[0]:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_res, label='test_res', color='k')\n",
    "plt.plot(garch_mean-np.sqrt(garch_var), color=plt.cm.tab10(0), label='garch_std')\n",
    "plt.plot(garch_mean+np.sqrt(garch_var), color=plt.cm.tab10(0))\n",
    "plt.plot(garch_mean, color=plt.cm.tab10(1), label='garch_mean')\n",
    "plt.xlim([0,500])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process output\n",
    "garch_std = np.sqrt(garch_var)[...,None]\n",
    "garch_ci_low = y_scaler.inverse_transform(preds-garch_std)\n",
    "garch_ci_hi = y_scaler.inverse_transform(preds+garch_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot garch results\n",
    "plot_PIs(y_test, y_hat, garch_ci_low, garch_ci_hi, x_lims=[168,336], label_pi='$\\hat{\\sigma}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to notice that now the area in blue is not a confidence interval, but rather the predicted standard deviation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
